{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bde45e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_inpurt: tensor([[[[0.0568, 0.3616, 0.8370],\n",
      "          [0.5148, 0.6241, 0.9322],\n",
      "          [0.9141, 0.0634, 0.3445]],\n",
      "\n",
      "         [[0.7159, 0.5276, 0.8828],\n",
      "          [0.0875, 0.0706, 0.6873],\n",
      "          [0.3516, 0.8273, 0.1722]]]])\n",
      "weight tensor of conv layer:\n",
      "Parameter containing:\n",
      "tensor([[[1, 0],\n",
      "         [0, 1]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [1, 0]]], requires_grad=True)\n",
      "conv_x: tensor([[[[0.8103, 0.0000],\n",
      "          [0.0000, 1.0176]],\n",
      "\n",
      "         [[0.2088, 1.0368],\n",
      "          [0.0000, 0.4031]]]], grad_fn=<ReluBackward1>)\n",
      "conv_x_size: torch.Size([1, 2, 2, 2])\n",
      "adaptive_avg_pool2d_x: tensor([[[[0.4570]],\n",
      "\n",
      "         [[0.4122]]]], grad_fn=<MeanBackward1>)\n",
      "adaptive_avg_pool2d_x_size: torch.Size([1, 2, 1, 1])\n",
      "reshape_x: tensor([[0.4570, 0.4122]], grad_fn=<ViewBackward>)\n",
      "reshape_x_size: torch.Size([1, 2])\n",
      "output: tensor([[-0.4866,  0.2273,  0.1762,  0.1512]], grad_fn=<AddmmBackward>)\n",
      "output_size: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ConvM(nn.Sequential):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1):\n",
    "        padding = (kernel_size - 1) // 2        \n",
    "\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        super(ConvM, self).__init__(            \n",
    "\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
    "            norm_layer(out_planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        conv=nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False)\n",
    "\n",
    "        replace_weight = torch.tensor([[[1,0],\n",
    "                                       [0,1]],\n",
    "                                       [[0,1],\n",
    "                                       [1,0]]])\n",
    "        #replace_bias = torch.tensor([100000])\n",
    "\n",
    "        conv.weight.data=replace_weight\n",
    "        #conv.bias.data=replace_bias\n",
    "\n",
    "        print('weight tensor of conv layer:\\n{}'.format(conv.weight))\n",
    "        #print('bias tensor of conv layer:\\n{}'.format(conv.bias)) \n",
    "\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            ConvM(2, 2, 2, 1)                                         \n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(2, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        print(\"conv_x:\",x)                       \n",
    "        print(\"conv_x_size:\",x.size())                         #1*2*2*2\n",
    "        #print(\"conv_x.shape[0]:\",x.shape[0])\n",
    "        #print(\"conv_x.shape[1]:\",x.shape[1])\n",
    "        #print(\"conv_x.shape[2]:\",x.shape[2])\n",
    "        #print(\"conv_x.shape[3]:\",x.shape[3])\n",
    "\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, 1)\n",
    "        print(\"adaptive_avg_pool2d_x:\",x)                                    \n",
    "        print(\"adaptive_avg_pool2d_x_size:\",x.size())          #1*2*1*1\n",
    "        #print(\"adaptive_avg_pool2d_x.shape[0]:\",x.shape[0])\n",
    "        #print(\"adaptive_avg_pool2d_x.shape[1]:\",x.shape[1])\n",
    "        #print(\"adaptive_avg_pool2d_x.shape[2]:\",x.shape[2])\n",
    "        #print(\"adaptive_avg_pool2d_x.shape[3]:\",x.shape[3])\n",
    "\n",
    "        x = x.reshape(x.shape[0], -1) \n",
    "        print(\"reshape_x:\",x)\n",
    "        print(\"reshape_x_size:\",x.size())       #轉成二維 1*2(降維)                \n",
    "        #print(\"reshape_x:\",x.shape[0])\n",
    "        #print(\"reshape_x:\",x.shape[1])\n",
    "\n",
    "        output = self.fc(x)           \n",
    "        print(\"output:\",output)               \n",
    "        print(\"output_size:\",output.size())     #轉成二維 1*4(分類)\n",
    "\n",
    "        return output\n",
    "\n",
    "dummy_inpurt = torch.rand(1,2,3,3)\n",
    "print(\"dummy_inpurt:\",dummy_inpurt)\n",
    "\n",
    "model = ConvNet(n_class=4)\n",
    "out = model(dummy_inpurt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa716c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 1, 1])\n",
      "1\n",
      "32\n",
      "1\n",
      "1\n",
      "torch.Size([1, 32])\n",
      "1\n",
      "32\n",
      "tensor([[0.3220, 0.3607, 0.2978]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class ConvM(nn.Sequential):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1):\n",
    "        padding = (kernel_size - 1) // 2        \n",
    "\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        super(ConvM, self).__init__(            \n",
    "\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
    "            norm_layer(out_planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_class=3):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            ConvM(3, 32, 5, 2),        #32*5*5            \n",
    "            ConvM(32, 64, 5, 2),       #64*3*3\n",
    "            ConvM(64, 128, 3, 1),      #128*3*3\n",
    "            ConvM(128, 64, 3, 1),      #64*3*3\n",
    "            ConvM(64, 32, 3, 1),       #32*3*3     \n",
    "        )        \n",
    "        self.fc = nn.Linear(32, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        #print(x)                       #32*3*3  \n",
    "\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, 1)\n",
    "        #print(x)                       #1*32*1*1             \n",
    "        print(x.size())\n",
    "        print(x.shape[0])\n",
    "        print(x.shape[1])\n",
    "        print(x.shape[2])\n",
    "        print(x.shape[3])\n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)  #轉成二維 1*32\n",
    "        #print(x)\n",
    "        print(x.size())\n",
    "        print(x.shape[0])\n",
    "        print(x.shape[1])\n",
    "\n",
    "        output = self.fc(x)            #轉成二維 1*3\n",
    "        print(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "model = ConvNet(n_class=3)\n",
    "dummy_inpurt = torch.rand(1,3,10,10)  \n",
    "out = model(dummy_inpurt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f8bd76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
